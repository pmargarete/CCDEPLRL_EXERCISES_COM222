{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmargarete/CCDEPLRL_EXERCISES_COM222/blob/main/Exercise5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "SjWNWZH3ti-A"
      },
      "id": "SjWNWZH3ti-A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c4d8cb",
      "metadata": {
        "id": "91c4d8cb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image  # PIL is used to load the image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "BbP9rY5Ptl7r"
      },
      "id": "BbP9rY5Ptl7r"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pScU5b0vq4os",
        "outputId": "75be5d81-6579-45e2-bc2e-57bf0c51cd9d"
      },
      "id": "pScU5b0vq4os",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display an image to test if the mount is successful"
      ],
      "metadata": {
        "id": "xgoIIzu3tod8"
      },
      "id": "xgoIIzu3tod8"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/midterm\"\n",
        "image_dir = os.path.join(dataset_path, \"images\")\n",
        "label_dir = os.path.join(dataset_path, \"labels\")"
      ],
      "metadata": {
        "id": "Ydec1mmn0Qq6"
      },
      "id": "Ydec1mmn0Qq6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def displayImage(image_path):\n",
        "  # Path to your image file in Google Drive\n",
        "  image = Image.open(image_path)\n",
        "\n",
        "  # Display the image using matplotlib\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')  # Hide axes for cleaner display\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "N9j13-RNs7xe"
      },
      "id": "N9j13-RNs7xe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displayImage('/content/drive/My Drive/midterm/images/IMG_6536_jpeg.rf.380db67db7043ded535303c916345aff.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "V6uO9mOls9sB",
        "outputId": "81184ad6-dbb4-47bc-db73-433eba7302f7"
      },
      "id": "V6uO9mOls9sB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/midterm/images/IMG_6536_jpeg.rf.380db67db7043ded535303c916345aff.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7470d1442c86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplayImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/midterm/images/IMG_6536_jpeg.rf.380db67db7043ded535303c916345aff.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-205e3fab53cc>\u001b[0m in \u001b[0;36mdisplayImage\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplayImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Path to your image file in Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Display the image using matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/midterm/images/IMG_6536_jpeg.rf.380db67db7043ded535303c916345aff.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if GPU is used"
      ],
      "metadata": {
        "id": "ivGN6sQKtqeR"
      },
      "id": "ivGN6sQKtqeR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5196e4c5",
      "metadata": {
        "id": "5196e4c5"
      },
      "outputs": [],
      "source": [
        "# Check if TensorFlow can access the GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    print(f\"TensorFlow is using GPU: {physical_devices[0]}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the image size"
      ],
      "metadata": {
        "id": "Vuvw39MEGDwb"
      },
      "id": "Vuvw39MEGDwb"
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 640\n",
        "image_size = (SIZE, SIZE)"
      ],
      "metadata": {
        "id": "PtuabMZ_uXxY"
      },
      "id": "PtuabMZ_uXxY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y_class = []\n",
        "y_bbox = []\n",
        "class_ids = set()"
      ],
      "metadata": {
        "id": "pWHs1ifx0t6s"
      },
      "id": "pWHs1ifx0t6s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the images and annotations"
      ],
      "metadata": {
        "id": "Lq3z8ygQ9QEi"
      },
      "id": "Lq3z8ygQ9QEi"
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        label_path = os.path.join(label_dir, os.path.splitext(filename)[0] + \".txt\")\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = img / 255.0\n",
        "\n",
        "        # Load annotation\n",
        "        with open(label_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls = int(parts[0])\n",
        "            bbox = list(map(float, parts[1:]))\n",
        "\n",
        "            X.append(img)\n",
        "            y_class.append(cls)\n",
        "            y_bbox.append(bbox)\n",
        "            class_ids.add(cls)\n",
        "\n",
        "X = np.array(X, dtype=np.float32)"
      ],
      "metadata": {
        "id": "f2gFiAews5d3"
      },
      "id": "f2gFiAews5d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map class IDs to indices\n",
        "class_ids = sorted(list(class_ids))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_ids)}\n",
        "num_classes = len(class_ids)\n",
        "\n",
        "# # One-hot encode class labels\n",
        "y_class = [class_to_idx[c] for c in y_class]\n",
        "y_class = to_categorical(y_class, num_classes=num_classes)\n",
        "\n",
        "y_bbox = np.array(y_bbox, dtype=np.float32)"
      ],
      "metadata": {
        "id": "89r7plmf01-_"
      },
      "id": "89r7plmf01-_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset"
      ],
      "metadata": {
        "id": "YEEOg2zn9xs1"
      },
      "id": "YEEOg2zn9xs1"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_cls_train, y_cls_test, y_bbox_train, y_bbox_test = train_test_split(X, y_class, y_bbox, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xpgsrRyPt09q"
      },
      "id": "xpgsrRyPt09q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Convolutional Neural Network"
      ],
      "metadata": {
        "id": "r8dpB2a_93Et"
      },
      "id": "r8dpB2a_93Et"
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(SIZE, SIZE, 3))\n",
        "\n",
        "x = layers.Conv2D(32, (3,3), activation='relu')(input_layer)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Output 1: class probabilities\n",
        "class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(x)\n",
        "\n",
        "# Output 2: bounding box (x_center, y_center, width, height)\n",
        "bbox_output = layers.Dense(4, activation='sigmoid', name='bbox_output')(x)\n",
        "\n",
        "model = models.Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'class_output': 'categorical_crossentropy', 'bbox_output': 'mse'},\n",
        "    metrics={'class_output': 'accuracy'}\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PrTBnNi8v_rX"
      },
      "id": "PrTBnNi8v_rX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    {'class_output': y_cls_train, 'bbox_output': y_bbox_train},\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "kZxsjacH5_JJ"
      },
      "id": "kZxsjacH5_JJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "PNjhygWB-GQL"
      },
      "id": "PNjhygWB-GQL"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, {'class_output': y_cls_test, 'bbox_output': y_bbox_test})"
      ],
      "metadata": {
        "id": "PFTtHrpE5_fQ"
      },
      "id": "PFTtHrpE5_fQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model using the test set"
      ],
      "metadata": {
        "id": "39C5Qq0j-Imt"
      },
      "id": "39C5Qq0j-Imt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Separate class and bounding box predictions\n",
        "y_cls_pred = y_pred[0]  # The class prediction (probabilities)\n",
        "y_bbox_pred = y_pred[1]  # The bounding box prediction (x_center, y_center, width, height)"
      ],
      "metadata": {
        "id": "7IulGvyv8Bll"
      },
      "id": "7IulGvyv8Bll",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize one image prediction"
      ],
      "metadata": {
        "id": "jH8IE7mMFtN9"
      },
      "id": "jH8IE7mMFtN9"
    },
    {
      "cell_type": "code",
      "source": [
        "index = 20\n",
        "img = X_test[20]\n",
        "\n",
        "# Rescale the bounding box predictions (back to original size)\n",
        "img_height, img_width, _ = img.shape\n",
        "predicted_bbox = y_bbox_pred[index]\n",
        "\n",
        "# Convert normalized bbox to pixel coordinates (0 to img_width / img_height)\n",
        "x_center = predicted_bbox[0] * img_width\n",
        "y_center = predicted_bbox[1] * img_height\n",
        "width = predicted_bbox[2] * img_width\n",
        "height = predicted_bbox[3] * img_height\n",
        "\n",
        "# Get the top-left and bottom-right corners of the bounding box\n",
        "x1 = int(x_center - width / 2)\n",
        "y1 = int(y_center - height / 2)\n",
        "x2 = int(x_center + width / 2)\n",
        "y2 = int(y_center + height / 2)\n",
        "\n",
        "# Show the predicted class\n",
        "predicted_class = np.argmax(y_cls_pred, axis=1)\n",
        "predicted_class_name = class_ids[predicted_class[index]]\n",
        "\n",
        "img = cv2.resize(img, image_size)\n",
        "img_display = (img * 255).astype(np.uint8).copy()\n",
        "\n",
        "color = (0, 255, 0)  # Green box\n",
        "thickness = 5\n",
        "\n",
        "# Draw rectangle\n",
        "cv2.rectangle(img_display, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "# Choose font\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "font_scale = 0.5\n",
        "font_thickness = 1\n",
        "\n",
        "# Get text size to draw background\n",
        "(text_width, text_height), _ = cv2.getTextSize(str(predicted_class_name), font, font_scale, font_thickness)\n",
        "\n",
        "# Draw filled rectangle behind text\n",
        "cv2.rectangle(img_display, (x1, y1 - text_height - 4), (x1 + text_width, y1), color, -1)\n",
        "\n",
        "# Draw text (white text on top of the box)\n",
        "cv2.putText(img_display, str(predicted_class_name), (x1, y1 - 2), font, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA)\n",
        "\n",
        "plt.imshow(img_display)\n",
        "plt.axis(\"off\")\n",
        "plt.title(predicted_class_name)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h0s5PUrn7A-D"
      },
      "id": "h0s5PUrn7A-D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict on test data"
      ],
      "metadata": {
        "id": "ypRXPfVRF8LR"
      },
      "id": "ypRXPfVRF8LR"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Separate the predictions\n",
        "y_cls_pred = y_pred[0]  # Class probabilities\n",
        "y_bbox_pred = y_pred[1]  # Bounding box predictions\n",
        "\n",
        "# Find the predicted class for each sample\n",
        "predicted_classes = np.argmax(y_cls_pred, axis=1)\n",
        "\n",
        "# Compare with true class labels (just for class prediction)\n",
        "true_classes = np.argmax(y_cls_test, axis=1)\n",
        "\n",
        "# Calculate accuracy (for class prediction)\n",
        "class_accuracy = np.mean(predicted_classes == true_classes)\n",
        "print(f\"Class prediction accuracy: {class_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "9i_Kea988Szj"
      },
      "id": "9i_Kea988Szj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "qTiJV1GHF6PA"
      },
      "id": "qTiJV1GHF6PA"
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.keras')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "oxeupq2gXG6-"
      },
      "id": "oxeupq2gXG6-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}